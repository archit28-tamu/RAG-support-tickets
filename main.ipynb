{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Based Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTOR_DB_DIR = './vector_db'\n",
    "NUM_RELEVANT_DOCS = 3\n",
    "EMBEDDING_MODEL = 'paraphrase-MiniLM-L3-v2'\n",
    "LLM = 'meta/llama-3.1-8b-instruct'\n",
    "\n",
    "query = \"My account login is not working. I've tried resetting my password twice.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.schema import Document\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading API for NVIDIA AI ENDPOINTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading API Keys\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "support_tickets = load_json('data/support_tickets.json')\n",
    "knowledge_base = load_json('data/knowledge_base.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Ticket: My account login is not working. I've tried resetting my password twice.\n",
      "Relevant Knowledge: Category 1 - Login Issues - Login issues often occur due to incorrect passwords or account lockouts.\n",
      "Support Ticket: The app crashes every time I try to upload a photo.\n",
      "Relevant Knowledge: Category 2 - App Functionality - App crashes can be caused by outdated software or device incompatibility.\n",
      "Support Ticket: I was charged twice for my last subscription payment.\n",
      "Relevant Knowledge: Category 3 - Billing - Billing discrepancies may result from processing errors or duplicate transactions.\n",
      "Support Ticket: I can't find the option to change my profile picture.\n",
      "Relevant Knowledge: Category 4 - Account Management - Account management includes tasks such as changing profile information, linking social media accounts, and managing privacy settings.\n",
      "Support Ticket: The video playback is very laggy on my device.\n",
      "Relevant Knowledge: Category 5 - Performance Issues - Performance issues can be related to device specifications, network connectivity, or app optimization.\n"
     ]
    }
   ],
   "source": [
    "# Creating Document from json files\n",
    "\n",
    "docs = []\n",
    "\n",
    "for ticket, entry in zip(support_tickets, knowledge_base):\n",
    "    ticket_text = ticket['text']\n",
    "    relevant_knowledge = entry['content']\n",
    "    \n",
    "    combined_content = f\"Support Ticket: {ticket_text}\\nRelevant Knowledge: {relevant_knowledge}\"\n",
    "    \n",
    "    docs.append(combined_content)\n",
    "\n",
    "# To print the document\n",
    "for doc in docs:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [Document(page_content=combined_content) for combined_content in docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/architgpt28/miniconda3/envs/EdLight_RAG/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initializing the Embedding Model\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the vector database and retriever\n",
    "\n",
    "os.makedirs(VECTOR_DB_DIR, exist_ok=True)\n",
    "vector_db_path = os.path.join(VECTOR_DB_DIR, EMBEDDING_MODEL.split('/')[-1])\n",
    "\n",
    "# To check if the vector database exists\n",
    "\n",
    "if not os.path.exists(vector_db_path):\n",
    "\n",
    "    print(f'Creating Vector Database at {vector_db_path}')\n",
    "    Chroma.from_documents(\n",
    "        documents=docs, \n",
    "        embedding=embedding_model, \n",
    "        persist_directory=vector_db_path\n",
    "    )\n",
    "\n",
    "db = Chroma(\n",
    "    persist_directory=vector_db_path,\n",
    "    embedding_function=embedding_model\n",
    ")\n",
    "\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\":NUM_RELEVANT_DOCS}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Ticket: My account login is not working. I've tried resetting my password twice.\n",
      "Relevant Knowledge: Category 1 - Login Issues - Login issues often occur due to incorrect passwords or account lockouts.\n",
      "Support Ticket: I can't find the option to change my profile picture.\n",
      "Relevant Knowledge: Category 4 - Account Management - Account management includes tasks such as changing profile information, linking social media accounts, and managing privacy settings.\n",
      "Support Ticket: I was charged twice for my last subscription payment.\n",
      "Relevant Knowledge: Category 3 - Billing - Billing discrepancies may result from processing errors or duplicate transactions.\n"
     ]
    }
   ],
   "source": [
    "# retrieving the relevant docs\n",
    "\n",
    "retrieved_docs = retriever.get_relevant_documents(query)\n",
    "\n",
    "# To print the retireved chunks of document\n",
    "for doc in retrieved_docs:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the LLM using NVIDIA ENDPOINTS\n",
    "\n",
    "llm = ChatNVIDIA(model = LLM, temperature=0.1, max_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the prompt for LLM\n",
    "\n",
    "classification_system_prompt = \"\"\"You are an assistant for classifying support tickets. Based on the following retrieved support tickets and their corresponding knowledge base categories, classify the given query into the most similar category. Only return the category name and number, nothing else.\n",
    "\n",
    "Retrieved tickets and categories:\n",
    "{retrieved_docs}\n",
    "\n",
    "Query to classify: {query}\n",
    "\n",
    "Classify the query and respond with only the category name and number. For example, if the query is similar to a login issue, respond with just 'Category 1 - Login Issues'. Only respond from what is mentioned in relevant knowledge and do not generate new text. Only use direct text from relevant knowledge for output.\"\"\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=classification_system_prompt),\n",
    "    HumanMessage(content=query)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Category 1 - Login Issues' response_metadata={'role': 'assistant', 'content': 'Category 1 - Login Issues', 'token_usage': {'prompt_tokens': 159, 'total_tokens': 165, 'completion_tokens': 6}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-8b-instruct'} id='run-f0417328-438d-4d3b-b5a5-40805dbe935c-0' role='assistant'\n",
      "\n",
      "Model Runtime: 0.34106922149658203 Seconds\n"
     ]
    }
   ],
   "source": [
    "# Invoking the LLM and timming the result\n",
    "\n",
    "start = time.time()\n",
    "classification = llm(messages)\n",
    "end = time.time()\n",
    "\n",
    "print(classification)\n",
    "\n",
    "time = end - start\n",
    "print(f'\\nModel Runtime: {time} Seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EdLight_RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
