{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTOR_DB_DIR = './vector_db'\n",
    "NUM_RELEVANT_DOCS = 1\n",
    "EMBEDDING_MODEL = 'paraphrase-MiniLM-L3-v2'\n",
    "CLASSIFICATION_MODEL = \"facebook/bart-large-mnli\"\n",
    "\n",
    "query = \"Cannot find my payment receipt for subscription\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/architgpt28/miniconda3/envs/EdLight_RAG/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.schema import Document\n",
    "import json\n",
    "from transformers import pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "support_tickets = load_json('data/support_tickets.json')\n",
    "knowledge_base = load_json('data/knowledge_base.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Ticket: My account login is not working. I've tried resetting my password twice.\n",
      "Relevant Knowledge: Category 1 - Login Issues - Login issues often occur due to incorrect passwords or account lockouts.\n",
      "Support Ticket: The app crashes every time I try to upload a photo.\n",
      "Relevant Knowledge: Category 2 - App Functionality - App crashes can be caused by outdated software or device incompatibility.\n",
      "Support Ticket: I was charged twice for my last subscription payment.\n",
      "Relevant Knowledge: Category 3 - Billing - Billing discrepancies may result from processing errors or duplicate transactions.\n",
      "Support Ticket: I can't find the option to change my profile picture.\n",
      "Relevant Knowledge: Category 4 - Account Management - Account management includes tasks such as changing profile information, linking social media accounts, and managing privacy settings.\n",
      "Support Ticket: The video playback is very laggy on my device.\n",
      "Relevant Knowledge: Category 5 - Performance Issues - Performance issues can be related to device specifications, network connectivity, or app optimization.\n"
     ]
    }
   ],
   "source": [
    "# Creating Document from json files\n",
    "\n",
    "docs = []\n",
    "\n",
    "for ticket, entry in zip(support_tickets, knowledge_base):\n",
    "    ticket_text = ticket['text']\n",
    "    relevant_knowledge = entry['content']\n",
    "    \n",
    "    combined_content = f\"Support Ticket: {ticket_text}\\nRelevant Knowledge: {relevant_knowledge}\"\n",
    "    \n",
    "    docs.append(combined_content)\n",
    "\n",
    "# To print the document\n",
    "for doc in docs:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [Document(page_content=combined_content) for combined_content in docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/architgpt28/miniconda3/envs/EdLight_RAG/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initializing the Embedding Model\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the vector database and retriever\n",
    "\n",
    "os.makedirs(VECTOR_DB_DIR, exist_ok=True)\n",
    "vector_db_path = os.path.join(VECTOR_DB_DIR, EMBEDDING_MODEL.split('/')[-1])\n",
    "\n",
    "# To check if the vector database exists\n",
    "if not os.path.exists(vector_db_path):\n",
    "\n",
    "    print(f'Creating Vector Database at {vector_db_path}')\n",
    "    Chroma.from_documents(\n",
    "        documents=docs, \n",
    "        embedding=embedding_model, \n",
    "        persist_directory=vector_db_path\n",
    "    )\n",
    "\n",
    "db = Chroma(\n",
    "    persist_directory=vector_db_path,\n",
    "    embedding_function=embedding_model\n",
    ")\n",
    "\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\":NUM_RELEVANT_DOCS}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/architgpt28/miniconda3/envs/EdLight_RAG/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# retrieving the relevant docs\n",
    "\n",
    "retrieved_docs = retriever.get_relevant_documents(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/architgpt28/miniconda3/envs/EdLight_RAG/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# creating the labels for the classification categories\n",
    "\n",
    "knowledge_categories = [\n",
    "    \"Category 1 - Login Issues\",\n",
    "    \"Category 2 - App Functionality\",\n",
    "    \"Category 3 - Billing\",\n",
    "    \"Category 4 - Account Management\",\n",
    "    \"Category 5 - Performance Issues\"\n",
    "]\n",
    "\n",
    "# Initializing the model\n",
    "\n",
    "# classification_model = pipeline(\"text-classification\", model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "classification_model = pipeline(\"zero-shot-classification\", model=CLASSIFICATION_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoking the classification_model to generate output\n",
    "\n",
    "def classify_ticket(query, retrieved_docs):\n",
    "    context = \" \".join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "    # return context\n",
    "    \n",
    "    prediction = classification_model(query, candidate_labels=knowledge_categories, hypothesis_template=f\"This text is about {{}}. {context}\")\n",
    "    return prediction['labels'][0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Category: Category 3 - Billing\n"
     ]
    }
   ],
   "source": [
    "# Calling the classification function and printing the result\n",
    "\n",
    "predicted_category = classify_ticket(query, retrieved_docs)\n",
    "\n",
    "print(f\"Predicted Category: {predicted_category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
